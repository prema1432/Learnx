# üåü Welcome to the Python Gen AI RAG Bot üåü

## üöÄ Introduction

The **Python Gen AI RAG Bot** is an advanced Retrieval-Augmented Generation (RAG) system, designed to combine the power
of large language models with a knowledge retrieval mechanism. This bot helps retrieve contextually accurate information
from your documents and generates intelligent responses. Whether you're building intelligent conversational agents or
integrating AI into applications, this bot is an excellent choice!

---

## üõ†Ô∏è Installation

Follow the steps below to set up and run the Python Gen AI RAG Bot on your local machine:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/prema1432/Learnx.git
   ```
2. **Navigate to the project directory:**
    ```bash
   cd Learnx
    ```
3. Create and activate a virtual environment:
    - For Windows:
        ```bash
            python -m venv venv
            venv\Scripts\activate
        ```
    - For macOS/Linux:
        ```bash
            python3 -m venv venv
            source venv/bin/activate
        ```
4. **Install the required dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
5. **Install rrequiremennts in single fast way :**
    ```bash
    pip install streamlit langchain langchain_community  langchain-chroma pypdf docx2txt
    ```

6. **Set up environment variables:**
    ```bash
    touch .env
    ```
7. **Run the Streamlit application:**
    ```bash
    streamlit run learnx.py
    ```

## üõë Prerequisites

Before running the application, ensure that the following are installed on your system:

1. **Python 3.10+**
    - Make sure you have Python version 3.10 or higher installed. You can download it from
      the [official Python website](https://www.python.org/downloads/).

2. **Streamlit**
    - Install Streamlit to create interactive web applications. You can install it via pip:
      ```bash
      pip install streamlit
      ```

3. **LangChain**
    - LangChain is required for building language model applications. Install it using pip:
      ```bash
      pip install langchain
      ```

4. **ChromaDB**
    - Ensure ChromaDB is installed for managing document embeddings. Install it with:
      ```bash
      pip install chromadb
      or 
      pip install langchain-chroma
      ```

5. **Gemini API Key**
    - Obtain your Gemini API Key to access the necessary features of the application. Follow the instructions on
      the [Gemini API documentation](https://aistudio.google.com/app) to get your key.

## üìö Languages & Frameworks

This application is built using the following technologies:

### üêç Python

Python is the backbone of this AI application, offering a flexible environment for machine learning and web development.
Its extensive libraries and community support make it an ideal choice for building AI models.
[Learn more](https://docs.python.org/3/)

### üìä Streamlit

Streamlit is a fast way to create beautiful and interactive web applications for machine learning models. It helps make
this bot accessible via a web interface, allowing users to interact seamlessly.
[Streamlit Documentation](https://docs.streamlit.io/)

### üîó LangChain

LangChain is a robust framework designed for building language model applications. It allows for the integration of
various components like chains, memory, and prompts to enhance the capabilities of the AI, making it more versatile and
powerful.
[LangChain Documentation](https://python.langchain.com/docs/introduction/)

### üß† ChromaDB

ChromaDB is a vector database used for storing and querying document embeddings, enabling the bot to retrieve the most
contextually relevant information quickly and efficiently.
[ChromaDB Documentation](https://docs.trychroma.com/)

### Additional Technologies

- **Docker**: Used for containerization, ensuring consistent environments across development and production.
- **Git**: Version control system that helps manage code changes and collaboration effectively.

## üåü Features

Our system boasts a range of powerful features designed to enhance user experience and efficiency:

1. **Real-time Document Retrieval**
    - Retrieve relevant information from a wide variety of document sources, ensuring users have access to the latest
      data.

2. **AI-Enhanced Responses**
    - Utilize large language models to generate responses that are both contextual and informative, improving the
      quality of interactions.

3. **Interactive Web Interface**
    - Powered by **Streamlit**, this interface allows for easy and dynamic interaction with the bot, providing a
      user-friendly experience.

4. **Flexible Framework**
    - Built with **LangChain**, making it simple to customize or extend the bot‚Äôs capabilities to meet specific needs.

5. **Efficient Vector Search**
    - Leverage **ChromaDB** to store document embeddings for efficient and fast retrieval, ensuring quick access to
      relevant information.

## üéØ Future Improvements

We are continuously working on enhancing our system. Here are some key areas for future development:

1. **Support for Multiple Language Models**
    - Integrate various models such as GPT, BERT, etc., to provide users with a broader range of capabilities.

2. **Improved Vector Search Efficiency**
    - Optimize ChromaDB settings to enhance the efficiency of vector search, making it faster and more accurate.

3. **Enhanced User Interface**
    - Revamp the UI for better interaction and usability, ensuring that users can navigate seamlessly.

4. **Integration of External Knowledge Sources**
    - Implement advanced web scraping techniques to gather real-time data from various sources, enhancing the model's
      knowledge base.
    - Utilize libraries like BeautifulSoup and Scrapy for efficient data extraction and processing.

5. **Support for Fine-Tuned Models**
    - Add capabilities for fine-tuning models to cater to specific use cases, allowing for personalized user
      experiences.

6. **Advanced Web Scraping Features**
    - Implement features for handling dynamic content using tools like Selenium.
    - Develop strategies for managing rate limits and avoiding IP bans during scraping.
    - Incorporate natural language processing (NLP) techniques to analyze and summarize scraped content effectively.

### Conclusion

By focusing on these improvements, we aim to enhance the overall performance and user experience of our system. Your
feedback is invaluable in guiding these developments!

## üôã‚Äç‚ôÇÔ∏è Questions?

If you have any questions, feel free to:

- Reach out via **Email**: [talamarlapremanath143@gmail.com](mailto:talamarlapremanath143@gmail.com)

